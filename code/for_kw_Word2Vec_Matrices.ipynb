{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"for_kw_Word2Vec_Matrices.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"EJI5MCkdbbkV"},"source":["# pip install xlsxwriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vX5qMYWQdiep"},"source":["import gensim\n","from gensim import corpora\n","from gensim.models import Word2Vec\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","import csv\n","# import xlsxwriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vUD3UwcOvZIU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636714398982,"user_tz":-180,"elapsed":19989,"user":{"displayName":"Иван Мамаев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14348806989212286802"}},"outputId":"6997942c-6685-4e5a-84ad-9bcf9db3e41b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"HbW6rNoqnc4R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636714413800,"user_tz":-180,"elapsed":3257,"user":{"displayName":"Иван Мамаев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14348806989212286802"}},"outputId":"f20d1731-9083-491b-9058-89e2de78d611"},"source":["%%time\n","df = pd.read_csv('./drive/MyDrive/sample_kw_distrib_table.tsv', sep = '\\t', \n","                 index_col = 0, header = [0,1,2])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 2.07 s, sys: 119 ms, total: 2.19 s\n","Wall time: 2.99 s\n"]}]},{"cell_type":"code","metadata":{"id":"xnNEbBZlQVd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636714427522,"user_tz":-180,"elapsed":250,"user":{"displayName":"Иван Мамаев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14348806989212286802"}},"outputId":"e34fad37-727d-422f-97a9-e8464760bf35"},"source":["lst = []\n","for line in df.columns:\n","  sub = [line[0], line[1], line[2]]\n","  lst.append(sub)\n","print(len(lst))\n","print(lst[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7280\n","['я_PRON', 'ваш', 'DET']\n"]}]},{"cell_type":"code","metadata":{"id":"XJ6jvUwHxiks"},"source":["raw_list =[]\n","\n","for index, rows in df.iterrows():\n","    # Create list for the current row\n","    my_list =[rows.я_PRON]\n","    print(my_list)\n","      \n","    # append the list to the final list\n","    raw_list.append(my_list)\n","print(len(raw_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tL3xYl6pZ3tW"},"source":["foo = './drive/MyDrive/fpi_1045/'\n","#foo = './drive/MyDrive/rscf/rusidiolect_data/processed_spacy/fpi_1045/'\n","fns = os.listdir(foo)\n","fns1 = [x[:-4].split('_') for x in fns]\n","len(fns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yu7c3aKzyxb1","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1636714448946,"user_tz":-180,"elapsed":631,"user":{"displayName":"Иван Мамаев","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14348806989212286802"}},"outputId":"171406bb-687a-4fdd-e0da-3a4ddd12d490"},"source":["final = []  # список для лемм типа lemma_POS\n","file_names = []  # список для названий файлов, чтобы удобнее было составить таблицу\n","kw_freq = []  # частота КС\n","c = 1\n","for name in sorted(fns):\n","  fn=foo + '/' + name  # путь к файлу\n","  with open(fn, newline='') as file:\n","    file_reader = csv.reader(file, delimiter=\",\")  # считываем файл\n","    lst = []  # подсписок для лемм определённого текста, который позже мы добавим в final\n","    for line in file_reader:\n","        lst.append(line[2]+'_'+line[3])  # соединяем лемму и часть речи\n","    final.append(lst)\n","    file_names.append(name)\n","    count_fr = []\n","    for kw in ['я_PRON']:      \n","      kw_freq.append(lst.count(kw))\n","  c += 1\n","  if c % 100 == 0:\n","   print(c) "],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-e986b9a2f9c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# подсписок для лемм определённого текста, который позже мы добавим в final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# соединяем лемму и часть речи\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfile_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"id":"Z3E9guw9daw8"},"source":["print(kw_freq)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWjVnvXLQ-_r","outputId":"02b242db-08e2-4634-b33b-b5b830283b9c"},"source":["len(raw_list[0][0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4994"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"EGvx7UBZRmIo"},"source":["r = raw_list[0][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NsZQVZMjR9I7"},"source":["r.sort_values(ascending=False)[:25]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZgOKHyt5n8A"},"source":["name_word_freq = []\n","t = 0\n","for raw in raw_list:  \n","  x = str(raw)\n","  f_name = re.findall('Name\\:.+\\, L', x)\n","  f_name = f_name[0].replace('Name: ', '')\n","  f_name = f_name.replace(', L', '')\n","  word_pos = raw[0].to_dict()\n","  freq = raw[0].tolist()\n","  for y, z in zip(word_pos, freq):\n","    to_add = [f_name, y[0]+'_'+y[1], z]\n","    t += 1\n","    #if t%100000 == 0:\n","    #  print(t)\n","    name_word_freq.append(to_add)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4nCM2-90Gzu"},"source":["# model=Word2Vec.load('./drive/MyDrive/ruscorpora_1_300_10.bin')\n","# model=Word2Vec.load('./drive/MyDrive/test_w2v_corpus.model')\n","# model=Word2Vec.load('./drive/MyDrive/web_0_300_20.bin')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZmF5t-gHIytD"},"source":["import gensim.models.keyedvectors as word2vec\n","\n","model=word2vec.KeyedVectors.load_word2vec_format('./drive/MyDrive/model.bin', \n","                                                 binary=True, unicode_errors='ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYarZ7C1eOuE"},"source":["kw_vectors = []\n","for i in sorted(name_word_freq):\n","  if int(i[2]) > 0:\n","    try:\n","      vector = model.wv[i[1]] * int(i[2])\n","      print(i)\n","      lst = [i[0], vector]\n","      kw_vectors.append(lst)\n","    except:\n","      pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eoBt-753oJEL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"09921367-ddad-4f02-dbd9-e1cc47872408"},"source":["len(kw_vectors)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19887"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"yFIoFP8wVL-E"},"source":["kw_vectors[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4t1g8ZLl2U1"},"source":["final_vect = []\n","vect = []\n","names_to_check = []\n","check = kw_one[0]\n","\n","for kw_one in kw_vectors:\n","\n","  # print(len(kw_one))\n","\n","  length = 0\n","  # print(check)\n","  if kw_one[0] == check:\n","    vect.append(kw_one[1])\n","    if check not in names_to_check:\n","      names_to_check.append(check)\n","  else:\n","    aver = sum(vect)/len(vect)\n","    to_add = [check, aver]\n","    final_vect.append(to_add)\n","    check = kw_one[0]\n","    vect = []\n","    vect.append(kw_one[1])\n","    if check not in names_to_check:\n","      names_to_check.append(check)\n","  length += 1\n","\n","  if length == len(final_vect):\n","    aver = sum(vect)/len(vect)\n","    to_add = [check, aver]\n","    final_vect.append(to_add)\n","    length = 0    \n","    if check not in names_to_check:\n","      names_to_check.append(check)\n","\n","#for name in file_names:\n","#  if name.replace('.csv', '') not in names_to_check:\n","#    to_add = [name.replace('.csv', ''), np.zeros(300,)]\n","#    final_vect.append(to_add)\n","\n","print(len(final_vect))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhuqZ-TB4awh"},"source":["rows = []  # подсписки с названиями файлов и частотами ключевых слов и контекстных векторых измерений\n","for x,in final_vect:\n","  one = []\n","  one.append(x[0])\n","  for i in x[1]:\n","    one.append(i)\n","  rows.append(one)\n","\n","print(len(rows))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gkewQAV84iVI"},"source":["first_row = [' ']  # первым рядом будет заголовок ключевого слова (сначала название текста, потом слово)\n","second_row = [' ']  # второй ряд посвящён векторным измерениям\n","\n","id_freq = 0\n","start_1 = 0\n","end_1 = 299\n","for test in ['я_PRON']:\n","    first_row.append(test)\n","    first_row.append(' ')\n","    for i in range(start_1, end_1):\n","      first_row.append(' ')\n","    second_row.append('count')\n","    dim = 1\n","    for i in range(start_1, end_1):\n","      second_row.append(dim)\n","      dim += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Edc1HUwN504f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5ee41dc-1272-4f3a-fab2-ea84d531c6f5"},"source":["print(len(rows[0]))\n","print(len(first_row))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["302\n","302\n"]}]},{"cell_type":"code","metadata":{"id":"_yCj3fItqbw3"},"source":["new_list = [first_row, second_row]\n","for r in rows:\n","  new_list.append(r)\n","\n","with xlsxwriter.Workbook('./drive/MyDrive/ruscorpora_1_300_10_test.xlsx') as workbook:\n","    worksheet = workbook.add_worksheet()\n","\n","    for row_num, data in enumerate(new_list):\n","        worksheet.write_row(row_num, 0, data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJvjRtl7VpKh","outputId":"9d116fb1-d5ad-4819-e820-f6235237d4f1"},"source":["%%time\n","df_1 = pd.read_excel('./drive/MyDrive/ruscorpora_1_300_10_test.xlsx', header=[0, 1], index_col=0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 2.36 s, sys: 8.69 ms, total: 2.37 s\n","Wall time: 2.37 s\n"]}]},{"cell_type":"code","metadata":{"id":"aE4kXrzjCGKX"},"source":["df_1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpW-McC2gV3Z"},"source":["import glob\n","\n","w = glob.glob('./drive/MyDrive/rusidiolect_data/processed_spacy/lex_contexts/big5_536/*.tsv')  # менять путь\n","\n","for way in w:\n","  df = pd.read_csv(way, sep = '\\t', index_col = 0, header = [0])\n","  lst = []\n","  way = way.replace('./drive/MyDrive/rusidiolect_data/processed_spacy/lex_contexts/big5_536/', '')\n","  way = way.replace('.tsv', '')\n","  for line in df.columns:\n","    try:\n","      line = line.split('_')\n","      sub = [way, line[0], line[1]]\n","      lst.append(sub)\n","    except:\n","      sub = [way, 'count', ' ']\n","      lst.append(sub)\n","\n","  raw_list =[]\n","\n","  for index, rows in df.iterrows():\n","      # Create list for the current row\n","      my_list =[]\n","      my_list.append(index)\n","      my_list.append(rows)\n","      \n","      # append the list to the final list\n","      raw_list.append(my_list)\n","  # print(len(raw_list))\n","\n","  filenames = []\n","  name_word_freq = []\n","  t = 0\n","  for raw in raw_list:  \n","    x = str(raw)\n","    f_name = raw[0]\n","    word_pos = raw[1].to_dict()\n","    freq = raw[1].tolist()\n","    for y, z in zip(word_pos.keys(), freq):\n","      to_add = [f_name, y, z]\n","      t += 1\n","      #if t%100000 == 0:\n","      #  print(t)\n","      name_word_freq.append(to_add)\n","    filenames.append(f_name)\n","\n","  import gensim.models.keyedvectors as word2vec\n","\n","  model=word2vec.KeyedVectors.load_word2vec_format('./drive/MyDrive/model.bin', binary=True, unicode_errors='ignore')\n","\n","  kw_vectors = []\n","  for i in sorted(name_word_freq):\n","    if int(i[2]) > 0:\n","      if i[1] in model.vocab:\n","        #vector = model.wv[i[1]] * int(i[2])\n","        c = 0\n","        while c < int(i[2]):\n","          vector = model.wv[i[1]]\n","          lst = [i[0], vector]\n","          kw_vectors.append(lst)\n","          c += 1\n","        #if way == 'я_PRON':\n","        #    if i[0] == '10_23_ж_0_повествование':\n","        #      print(i[1], i[2], model.wv[i[1]])\n","\n","  final_vect = []\n","  vect = []\n","  names_to_check = []\n","  check = kw_vectors[0][0]\n","\n","  length = 0\n","\n","  for kw_one in kw_vectors:\n","\n","    # print(len(kw_one))\n","\n","    # print(check)\n","    if check is kw_one[0]:\n","      vect.append(kw_one[1])\n","      if check not in names_to_check:\n","        names_to_check.append(check)\n","    else:\n","      aver = sum(vect)/len(vect)\n","      to_add = [check, aver]\n","      # print(to_add[0])  # имя файла\n","      final_vect.append(to_add)\n","      check = kw_one[0]\n","      vect = []\n","      vect.append(kw_one[1])\n","      if check not in names_to_check:\n","        names_to_check.append(check)\n","    length += 1\n","\n","    if length == len(kw_vectors):  # менять число (кол-во строк-текстов)\n","      aver = sum(vect)/len(vect)\n","      to_add = [check, aver]\n","      # print(to_add[0])\n","      final_vect.append(to_add)\n","      length = 0    \n","      if check not in names_to_check:\n","        names_to_check.append(check)\n","\n","  for name in sorted(filenames):\n","    if name not in names_to_check:\n","      to_add = [name, np.zeros(300,)]   \n","      final_vect.append(to_add)\n","\n","  print(len(final_vect))\n","\n","  rows = []  # подсписки с названиями файлов и частотами ключевых слов и контекстных векторых измерений\n","  for x in final_vect:\n","    one = []\n","    one.append(x[0])\n","    for i in x[1]:\n","      one.append(i)\n","    rows.append(one)\n","\n","  #print(len(rows))\n","\n","  first_row = [' ']  # первым рядом будет заголовок ключевого слова (сначала название текста, потом слово)\n","  second_row = [' ']  # второй ряд посвящён векторным измерениям\n","\n","  id_freq = 0\n","  start_1 = 0\n","  end_1 = 300\n","  for test in [way]:\n","      first_row.append(test)\n","      for i in range(start_1, end_1):\n","        first_row.append(' ')\n","      dim = 1\n","      for i in range(start_1, end_1):\n","        second_row.append(dim)\n","        dim += 1\n","\n","  #print(len(rows[0]))\n","  #print(len(first_row))\n","\n","  new_list = [first_row, second_row]\n","  for r in rows:\n","    new_list.append(r)\n","\n","  df_1 = pd.DataFrame(data=new_list)\n","  df_1.to_csv('./drive/MyDrive/rusidiolect_data/processed_spacy/w2v_contexts/big5_536/'+way+'.tsv', sep='\\t', index=False, header=False)\n","\n","  %%time\n","  # df_1 = pd.read_excel('./drive/MyDrive/w2v_contexts/big5_536/'+way+'.tsv', header=[0, 1], index_col=0)\n","\n","  print(way+' is ready!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GW3uEsIRl_dd"},"source":["model['деньга_NOUN']  # ЭТО ПОСЛЕДНЯЯ ВЕРСИЯ, ВАНЯ!!! 10.11.21"],"execution_count":null,"outputs":[]}]}